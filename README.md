**Xize Cheng (ÊàêÊõ¶Ê≥Ω)** is a Third-Year Master's student **(expected to graduate at 2024.03)** in the College of Computer Science and Software at [Zhejiang University](https://www.zju.edu.cn/english/), supervised by [Prof. Zhou Zhao](https://person.zju.edu.cn/zhaozhou).

**I am actively looking for academic collaboration, feel free to drop me an email.**

# üìé  HomePage

- Personal Pages: [https://exgc.github.io/](https://exgc.github.io/) (updated recentlyüî•)
- Google Scholar: [https://scholar.google.com.sg/citations?user=7w1U0l4AAAAJ](https://scholar.google.com.sg/citations?user=7w1U0l4AAAAJ)
  
# üî• News
- *2023.10*: üéâüéâ I am awarded National Scholarship (2023, Grauate student). Top 0.1% in Zhejiang University.
- *2023.09*: üéâüéâ 1 paper is accepted by EMNLP 2023!
- *2023.09*: üéâüéâ 1 paper is accepted by NIPS 2023!
- *2023.07*: üéâüéâ 1 Paper are accepted by ACMMM 2023!
- *2023.05*: üéâüéâ 3 Paper are accepted by ICCV 2023!
- *2023.06*: AV-TranSpeech comes out! Media coverage: [PaperWeekly](https://mp.weixin.qq.com/s/2KD8CYToz-mLZStwCXcSnA) and [ByteDance](https://mp.weixin.qq.com/s/SMUWbGqtyYRK6I_VW18hjA).
- *2023.05*: OpenSR will be presented in **oral** presentation at ACL2023!
- *2023.05*: üéâüéâ 7 Paper are accepted by ACL 2023!
- *2023.03*: We create the first Audio-Visual Multi-lingual Speech Translation dataset [AVMuST-TED ![](https://img.shields.io/github/stars/Exgc/AVMuST-TED?style=social)](https://github.com/Exgc/AVMuST-TED)! Soon to be open source!
- *2022.12*: [OpenSR](https://github.com/Exgc/OpenSR) is well regarded by the reviewers at October 2022 ACL-ARR.
- *2022.10*: I award the Outstanding Graduate Student and Triple Excellence Graduate Student of Zhejiang University!
- *2021.03*: I start my internship at Taobao as an algorithm intern, conducting multi-modality research.

# üìù Publications 

## Audio-Visual Speech

- [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation.]() **Xize Cheng**, Rongjie Huang, Linjun Li, Tao Jin, Zehan Wang, Aoxiong Yin, Minglei Li, Xinyu Duan, changpeng yang, Zhou Zhao. **submitted to ICLR2024**

- [MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup for Visual Speech Translation and Recognition.](https://arxiv.org/abs/2303.05309) **Xize Cheng**, Tao Jin, Rongjie Huang, Linjun Li, Wang Lin, Zehan Wang, Huadai Liu, Ye Wang, Aoxiong Yin, Zhou Zhao. **ICCV2023**

- [OpenSR: Open-Modality Speech Recognition via Maintaining Multi-Modality Alignment.](https://arxiv.org/abs/2306.06410) **Xize Cheng**, Tao Jin, Linjun Li, Wang Lin, Xinyu Duan, Zhou Zhao. **ACL2023(Oral)**

- [AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation.](https://arxiv.org/abs/2305.15403) Rongjie Haung\*, **Xize Cheng**\*, Huadai Liu\*, Yi Ren, Linjun Li, Zhenhui Ye, Jinzheng He, Lichao Zhang, Jinglin Liu, Xiang Yin, Zhou Zhao. **ACL2023**

- [Contrastive Token-Wise Meta-Learning for Unseen Performer Visual Temporal-Aligned Translation.](https://aclanthology.org/2023.findings-acl.699/) Linjun Li\*, Tao Jin\*, **Xize Cheng**\*, Ye Wang, Wang Lin, Rongjie Huang and Zhou Zhao. **ACL2023finding**

- [Rethinking Missing Modality Learning from a Decoding Perspective.](https://dl.acm.org/doi/abs/10.1145/3581783.3612291) Tao Jin, **Xize Cheng**, Linjun Li, Wang Lin, Ye Wang, Zhou Zhao. **ACMMM2023**
  
## Multi-modality Interpretation

- [Connecting Multi-modal Contrastive Representations.](https://arxiv.org/abs/2305.14381) Zehan Wang, Yang Zhao, **Xize Cheng**, Haifeng Huang, Jiageng Liu, Li Tang, Linjun Li, Yongqi Wang, Aoxiong Yin, Ziang Zhang, Zhou Zhao. **NIPS2023**

- [3drp-net: 3d relative position-aware network for 3d visual grounding.](https://arxiv.org/pdf/2307.13363) Zehan Wang, Haifeng Huang, Yang Zhao, Linjun Li, **Xize Cheng**, Yichen Zhu, Aoxiong Yin, Zhou Zhao. **EMNLP2023**

- [Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding.]() Zehan Wang, Haifeng Huang, Yang Zhao, **Xize Cheng**, Linjun Li, Yichen Zhu and Zhou Zhao. **ICCV2023**

- [Exploring Group Video Captioning with Efficient Relational Approximation.]() Wang Lin, Tao Jin, Ye Wang, Wenwen Pan, Linjun Li, **Xize Cheng**, Zhou Zhao **ICCV2023**
  
- [Weakly-Supervised Spoken Video Grounding via Semantic Interaction Learning.](https://aclanthology.org/2023.acl-long.611/) Ye Wang, Wang Lin, Shengyu Zhang, Tao Jin, Linjun Li, **Xize Cheng** and Zhou Zhao. **ACL2023(Oral)**

- [TAVT: Towards Transferable Audio-Visual Text Generation.](https://aclanthology.org/2023.acl-long.836) Wang Lin, Tao Jin, Wenwen Pan, Linjun Li, **Xize Cheng**, Ye Wang and Zhou Zhao. **ACL2023**

- [Semantic-conditioned Dual Adaptation for Cross-domain Query-based Visual Segmentation.](https://aclanthology.org/2023.findings-acl.621/) Ye Wang, Tao Jin, Wang Lin, **Xize Cheng**, Linjun Li and Zhou Zhao. **ACL2023finding**
